{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff687ea3",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "\n",
    "### Team Members:\n",
    " - Alex Lopez\n",
    " - Chris Haub\n",
    " - Erin McClure-Price\n",
    " - Chad Kwong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3f66b8",
   "metadata": {},
   "source": [
    "#### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a725e35e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-24c4bd060817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#import turicreate as tc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m \u001b[0;31m#EMP used for some outlier stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;31m#EMP used for some outlier stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "#import turicreate as tc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px #EMP used for some outlier stuff\n",
    "from scipy import stats #EMP used for some outlier stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd9a18",
   "metadata": {},
   "source": [
    "#### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce513607",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Loading all data file separately \n",
    "vle = pd.read_csv('./anonymiseddata/vle.csv')\n",
    "assessments = pd.read_csv('./anonymiseddata/assessments.csv')\n",
    "courses = pd.read_csv('./anonymiseddata/courses.csv')\n",
    "studentAssessments = pd.read_csv('./anonymiseddata/studentAssessment.csv')\n",
    "studentInfo = pd.read_csv('./anonymiseddata/studentInfo.csv')\n",
    "studentRegistration = pd.read_csv('./anonymiseddata/studentRegistration.csv')\n",
    "studentVle = pd.read_csv('./anonymiseddata/studentVle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946add74",
   "metadata": {},
   "source": [
    "# Business Understanding 1 #\n",
    "*Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). How will you measure the effectiveness of a good algorithm? Why does your chosen validation method make sense for this specific dataset and the stakeholders needs?*\n",
    "\n",
    "For Lab 3 we chose to use the \"Open University Learning Analytics Dataset\" (OULAD) which is an anonymized collection of information acquired from online students who were enrolled in the Open University (Milton Keynes, England) in 2013-2014. The data includes student demographic and registration information, as well as assessment results and interactions with the Virtual Learning Environment (VLE). There are multiple ways that the OULAD can be utilized, including prediction of grade results, better understanding of the factors that influence online student outcomes, or to compare online student results to in-person student results. The reason why this dataset is important is because it can be used by educators and universities to increase student success within an online learning environment. \n",
    "\n",
    "Our goal for Lab 3 was to explore the OULAD using K-Means clustering in order to find trends and insight into student learning styles. We chose K-Means clustering because it is an unsupervised algorithm that is straightforward to carry out, scalable, and can be used for large datasets. We chose to evaluate the clustering model using the **Dunn Index..?**, which calculates the closest distance between two clusters divided by the largest distance between two clusers. The Dunn Index has a range of 0 to 1, wherein the closer the value is to 1 the better the clustering. We felt that the Dunn Index was ideal because it provides a numeric value to the fitness of a cluster rather than through visual analysis.\n",
    "\n",
    "\n",
    "##### References\n",
    "[Kaggle: OULAD](https://www.kaggle.com/datasets/rocki37/open-university-learning-analytics-dataset)\n",
    "\n",
    "[K-Means Clustering and Dunn Index Implementaion \n",
    "From Scratch]( https://mayankdw.medium.com/k-means-clustering-and-dunn-index-implementaion-from-scratch-9c66573bfe90)\n",
    "\n",
    "[Dunn Index for K-Means Clustering Evaluation](https://python-bloggers.com/2022/03/dunn-index-for-k-means-clustering-evaluation/)\n",
    "\n",
    "[A Simple Explanation of K-Means Clustering](https://www.analyticsvidhya.com/blog/2020/10/a-simple-explanation-of-k-means-clustering/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a069ac",
   "metadata": {},
   "source": [
    "# Data Understanding 1 #\n",
    "*Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?*\n",
    "\n",
    "The OULAD contains seven CSV files that encompasses data collected from 32,593 students that were enrolled in 22 courses. There are a total of 43 variables and over **X** million instances. The CSV files and their contents are described below, information regarding each variable was taken from [HERE](https://analyse.kmi.open.ac.uk/open_dataset). It should be noted that \"modules\" refer to university courses and VLE refers to \"virtual learning environment\".\n",
    "\n",
    "#### Courses:\n",
    "* code_module **(categorical)** - code for the module, which serves as the identifier\n",
    "* code_presentation  **(categorical)**– code name of the presentation. It consists of the year and “B” for the presentation starting in February and “J” for the presentation starting in October.\n",
    "* length **(numeric)** - length of the module-presentation in days.\n",
    "\n",
    "#### Assessments\n",
    "* code_module **(categorical)** – identification code of the module, to which the assessment belongs.\n",
    "* code_presentation **(categorical)** - identification code of the presentation, to which the assessment belongs.\n",
    "* id_assessment **(numeric)** – identification number of the assessment.\n",
    "* assessment_type **(categorical)** – type of assessment. Three types of assessments exist: Tutor Marked Assessment (TMA), Computer Marked Assessment (CMA) and Final Exam (Exam).\n",
    "* date **(numeric)** – information about the final submission date of the assessment calculated as the number of days since the start of the module-presentation. The starting date of the presentation has number 0 (zero).\n",
    "* weight **(numeric)** - weight of the assessment in %. Typically, Exams are treated separately and have the weight 100%; the sum of all other assessments is 100%.\n",
    "\n",
    "#### VLE\n",
    "* id_site **(numeric)** – an identification number of the material.\n",
    "* code_module **(categorical)** – an identification code for module.\n",
    "* code_presentation **(categorical)** - the identification code of presentation.\n",
    "* activity_type **(categorical)** – the role associated with the module material.\n",
    "* week_from **(numeric)** – the week from which the material is planned to be used.\n",
    "* week_to **(numeric)** – week until which the material is planned to be used.;\n",
    "\n",
    "#### StudentInfo\n",
    "* code_module **(categorical)** – an identification code for a module on which the student is registered.\n",
    "* code_presentation **(categorical)** - the identification code of the presentation during which the student is registered on the module.\n",
    "* id_student **(numeric)** – a unique identification number for the student.\n",
    "* gender **(categorical)** – the student’s gender.\n",
    "* region **(categorical)** – identifies the geographic region, where the student lived while taking the module-presentation.\n",
    "* highest_education **(categorical)** – highest student education level on entry to the module presentation.\n",
    "* imd_band **(categorical)** – specifies the Index of Multiple Depravation band of the place where the student lived during the module-presentation.\n",
    "* age_band **(numeric)** – band of the student’s age.\n",
    "* num_of_prev_attempts **(numeric)** – the number times the student has attempted this module.\n",
    "* studied_credits **(numeric)** – the total number of credits for the modules the student is currently studying.\n",
    "* disability **(categorical)**  – indicates whether the student has declared a disability.\n",
    "* final_result **(categorical)** – student’s final result in the module-presentation.\n",
    "\n",
    "#### StudentRegistragion\n",
    "* code_module **(categorical)** – an identification code for a module.\n",
    "* code_presentation **(categorical)** - the identification code of the presentation.\n",
    "* id_student **(numeric)** – a unique identification number for the student.\n",
    "* date_registration **(numeric)** – the date of student’s registration on the module presentation, this is the number of days measured relative to the start of the module-presentation (e.g. the negative value -30 means that the student registered to module presentation 30 days before it started).\n",
    "* date_unregistration **(numeric)** – date of student unregistration from the module presentation, this is the number of days measured relative to the start of the module-presentation. Students, who completed the course have this field empty. Students who unregistered have Withdrawal as the value of the final_result column in the studentInfo.csv file.\n",
    "\n",
    "#### StudentAssessment\n",
    "* id_assessment **(numeric)** – the identification number of the assessment.\n",
    "* id_student **(numeric)** – a unique identification number for the student.\n",
    "* date_submitted **(numeric)** – the date of student submission, measured as the number of days since the start of the module presentation.\n",
    "* is_banked **(numeric)** – a status flag indicating that the assessment result has been transferred from a previous presentation.\n",
    "* score **(numeric)** – the student’s score in this assessment. The range is from 0 to 100. The score lower than 40 is interpreted as Fail. The marks are in the range from 0 to 100.\n",
    "\n",
    "#### StudentVLE\n",
    "* code_module **(categorical)** – an identification code for a module.\n",
    "* code_presentation **(categorical)** - the identification code of the module presentation.\n",
    "* id_student **(numeric)** – a unique identification number for the student.\n",
    "* id_site **(numeric)** - an identification number for the VLE material.\n",
    "* date **(numeric)** – the date of student’s interaction with the material measured as the number of days since the start of the module-presentation.\n",
    "* sum_click **(numeric)** – the number of times a student interacts with the material in that day.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69628dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vle.activity_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0992a3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a7577d3",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a0e39c",
   "metadata": {},
   "source": [
    " ## this is all stated in the cell above, keep here or above?\n",
    " \n",
    "The dataset was originally used in a relational database schema with separated tables, hence the seven CSV files. In order to create a clustering model, we needed to merge these tables together into a singular dataframe. The resulting dataset had over **x million instances** encompassing data from 32,593 students and we found that our machines were bogged down by the size, making it necessary to take a random sample of 1,000 students for a total of 2,705,197 instances. \n",
    "\n",
    "\n",
    " **below is the stuff that seems redundant (added some of it in the above paragraph too**\n",
    " - The data set was collected from students living in the UK\n",
    " - VLE stands for Virtual Learning Environment\n",
    " - VLE table records interactions with VLE \n",
    " - 32,593 students\n",
    " - 22 courses\n",
    "  \n",
    "  \n",
    "  we found that using all of the 32000 students was too intensive, so we sampled 4000 random students to create the dataframe from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52205b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Randomly sampling 4,000 records StudentVle Table with Million Rows.\n",
    "studentSample = studentInfo.sample(n=4000, random_state = 777)\n",
    "print(studentSample.shape)\n",
    "\n",
    "# vle\n",
    "# assessments X\n",
    "# courses X\n",
    "# studentAssessments X\n",
    "# studentInfo X\n",
    "# studentRegistration X\n",
    "# studentVleSample X\n",
    "\n",
    "df = pd.merge(studentSample, studentVle, on=['code_module', 'code_presentation', 'id_student'])\n",
    "df2 = pd.merge(studentAssessments, assessments, on='id_assessment')\n",
    "df = pd.merge(df, df2, on=['code_module', 'code_presentation', 'id_student'], how='left')\n",
    "df = pd.merge(df, courses, on= ['code_module', 'code_presentation'], how='left')\n",
    "df = pd.merge(df, studentRegistration, on=['code_module', 'code_presentation', 'id_student'], how='left')\n",
    "df = pd.merge(df, vle, on=['id_site', 'code_module', 'code_presentation'], how='left')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea4e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "The code below was used to ensure that we did not create any rows with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d3839",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb82a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "studentVle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a7b2ee",
   "metadata": {},
   "source": [
    "From the cell below, we saw that date_unregistration had null entries in over 96% of the data, and both week_from and week_to had null entries for over 86% of the data. Since these columns seemed to be unnecessary, we chose to drop all three as they consisted mostly of missing values. These columns could be used to analyze the population of the data that are not registered. **I don't understand this last sentence**\n",
    "\n",
    "Running the same code on the dataset after dropping the three columns showed that the percentages of missing values in the remaining columns were less than 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d385d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing values: \\n', df.isnull().sum() * 100 / len(df),'\\n\\n')\n",
    "df = df.drop(columns = ['week_from', 'week_to', 'date_unregistration'])\n",
    "print('Missing values after dopping columns: \\n', df.isnull().sum() * 100 / len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc3b66",
   "metadata": {},
   "source": [
    "From the code below, we can see that the missing values within the IMD Band variable come from the Northern Region and Ireland. The next step was to choose how best to deal with the missing values within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e74b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingIMDBand = df[df['imd_band'].isnull()]\n",
    "print(missingIMDBand.region.value_counts() * 100 / len(missingIMDBand))\n",
    "\n",
    "print('counts per region: \\n',missingIMDBand.region.value_counts(),'\\n\\n')\n",
    "print('percentage breakdown per region: \\n',missingIMDBand.region.value_counts() * 100 / len(missingIMDBand), '\\n\\n')\n",
    "\n",
    "northRegionMV = missingIMDBand.region.value_counts()[0]\n",
    "irelandMV = missingIMDBand.region.value_counts()[1]\n",
    "westMidRegionMV = missingIMDBand.region.value_counts()[2]\n",
    "southRegionMV = missingIMDBand.region.value_counts()[3]\n",
    "\n",
    "print('North Region percent of total: ',northRegionMV/len(df.region[df.region=='North Region']))\n",
    "print('Ireland percent of total: ',irelandMV/len(df.region[df.region=='Ireland']))\n",
    "print('West Midlands Region percent of total: ',westMidRegionMV/len(df.region[df.region=='West Midlands Region']))\n",
    "print('South Region percent of total: ',southRegionMV/len(df.region[df.region=='South Region']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b38df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.imd_band.value_counts(),\"\\n\\n\")\n",
    "\n",
    "print(df[(df.region=='North Region') | (df.region=='Ireland')].imd_band.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e90488",
   "metadata": {},
   "source": [
    "If we were particularly interested in examining regional differences, we theorized that we could calculate the most likely IMD_band value per region and fill in the missing values to match that distribution. However since the missing values only accounted for less than 8% of the total data, we chose to drop all the rows containing missing values, as data size requirements were still more than satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07718173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop(columns=['id_student','id_assessment','id_site','code_module','code_presentation'],inplace=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1deef1",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313fa14",
   "metadata": {},
   "source": [
    "As shown in the code output below, many of the variables in the OULAD were categorical making it necessary to One Hot Encode the data in order to analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b008c96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fe757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View unique values in each column\n",
    "# for col in df:\n",
    "#   print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating variables for indexing continuous and categorical variables\n",
    "conCol = ['id_student', 'id_site', 'date_x', 'sum_click', 'num_of_prev_attempts', \n",
    "          'studied_credits', 'id_assessment ', 'date_submitted', 'is_banked', 'score', 'date_y', 'weight']\n",
    "\n",
    "catCol = ['code_module', 'code_presentation', 'gender', 'region', 'highest_education', \n",
    "          'imd_band', 'age_band', 'disability', 'final_result', 'assessment_type' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Declaring Scalar object\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "#One hot encoding of ALL categorical variables\n",
    "OneHotDF = pd.get_dummies(df[catCol],drop_first=False)\n",
    "\n",
    "#Scaling non-encoded data\n",
    "conVar = df.select_dtypes(exclude='object')\n",
    "colnames = pd.Series(conVar.columns)\n",
    "conVarScaled = scl_obj.fit_transform(conVar)\n",
    "conVarScaled = pd.DataFrame(data = conVarScaled, columns= colnames)\n",
    "\n",
    "#Combining with continuous variables from cleaned dataset\n",
    "OneHotDF = OneHotDF.reset_index()\n",
    "OneHotDF.pop('index')\n",
    "OneHotDF = pd.concat([conVarScaled,OneHotDF], axis = 1)\n",
    "OneHotDF.head()\n",
    "\n",
    "#https://github.com/jakemdrew/DataMiningNotebooks/blob/master/01.%20Pandas.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7a3057",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "Once the OULAD was entirely numeric, we could look through the data for outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = OneHotDF.quantile(0.25)\n",
    "Q3 = OneHotDF.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edba66b",
   "metadata": {},
   "source": [
    "# Data Understanding 2 #\n",
    "*Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694dbac",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 1 #\n",
    "*Train and adjust parameters*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff4d53",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 2\t#\n",
    "*Evaluate and Compare*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080898dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y = OneHotDF['final_result_Pass']\n",
    "X = OneHotDF[['num_of_prev_attempts','studied_credits','disability_N']]\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "# run at n =100\n",
    "clf = RandomForestClassifier(n_estimators=2,random_state=1)\n",
    "\n",
    "acc = cross_val_score(clf,X,y=y,cv=cv)\n",
    "\n",
    "print (\"Average accuracy = \", acc.mean()*100, \"+-\", acc.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbab0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotDF.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40412ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHotDFDropNA = OneHotDF.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13032bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X1 = OneHotDFDropNA[['num_of_prev_attempts','final_result_Pass']]\n",
    "\n",
    "cls = KMeans(n_clusters=2, init='k-means++',random_state=1)\n",
    "cls.fit(X1)\n",
    "newfeature = cls.labels_ # the labels from kmeans clustering\n",
    "\n",
    "# y = OneHotDF['Survived']\n",
    "# X = OneHotDF[['Age','IsMale','Parch','SibSp']]\n",
    "# X = np.column_stack((X,pd.get_dummies(newfeature)))\n",
    "\n",
    "# acc = cross_val_score(clf,X,y=y,cv=cv)\n",
    "\n",
    "# print (\"Average accuracy (with kmeans for class/fare)= \", acc.mean()*100, \"+-\", acc.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f96566",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 3 #\n",
    "*Visualize Results*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497ac65",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 4 #\n",
    "*Summarize the Ramifications*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80334583",
   "metadata": {},
   "source": [
    "# Deployment #\n",
    "*Be critical of your performance and tell the reader how you current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling? How useful is your model for interested parties (i.e., the companies or organizations that might want to use it)? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a9f190",
   "metadata": {},
   "source": [
    "# Exceptional Work #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
